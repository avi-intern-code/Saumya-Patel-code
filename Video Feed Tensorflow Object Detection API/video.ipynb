{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, UpSampling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "import glob\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import subprocess\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow, figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize wandb and download dataset\n",
    "\n",
    "hyperparams = {\"num_epochs\": 10, \n",
    "          \"batch_size\": 32,\n",
    "          \"height\": 96,\n",
    "          \"width\": 96}\n",
    "\n",
    "wandb.init(config=hyperparams)\n",
    "config = wandb.config\n",
    "\n",
    "val_dir = 'catz/test'\n",
    "train_dir = 'catz/train'\n",
    "\n",
    "# automatically get the data if it doesn't exist\n",
    "if not os.path.exists(\"catz\"):\n",
    "    print(\"Downloading catz dataset...\")\n",
    "    subprocess.check_output(\n",
    "        \"curl https://storage.googleapis.com/wandb/catz.tar.gz | tar xz\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator to loop over train and test images\n",
    "\n",
    "def my_generator(batch_size, img_dir):\n",
    "    \"\"\"A generator that returns 5 images plus a result image\"\"\"\n",
    "    cat_dirs = glob.glob(img_dir + \"/*\")\n",
    "    counter = 0\n",
    "    while True:\n",
    "        input_images = np.zeros(\n",
    "            (batch_size, config.width, config.height, 3 * 5))\n",
    "        output_images = np.zeros((batch_size, config.width, config.height, 3))\n",
    "        random.shuffle(cat_dirs)\n",
    "        if (counter+batch_size >= len(cat_dirs)):\n",
    "            counter = 0\n",
    "        for i in range(batch_size):\n",
    "            input_imgs = glob.glob(cat_dirs[counter + i] + \"/cat_[0-5]*\")\n",
    "            imgs = [Image.open(img) for img in sorted(input_imgs)]\n",
    "            input_images[i] = np.concatenate(imgs, axis=2)\n",
    "            output_images[i] = np.array(Image.open(\n",
    "                cat_dirs[counter + i] + \"/cat_result.jpg\"))\n",
    "            input_images[i] /= 255.\n",
    "            output_images[i] /= 255.\n",
    "        yield (input_images, output_images)\n",
    "        counter += batch_size\n",
    "        \n",
    "steps_per_epoch = len(glob.glob(train_dir + \"/*\")) // config.batch_size\n",
    "validation_steps = len(glob.glob(val_dir + \"/*\")) // config.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback to log the images\n",
    "\n",
    "class ImageCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        validation_X, validation_y = next(\n",
    "            my_generator(15, val_dir))\n",
    "        output = self.model.predict(validation_X)\n",
    "        wandb.log({\n",
    "            \"input\": [wandb.Image(np.concatenate(np.split(c, 5, axis=2), axis=1)) for c in validation_X],\n",
    "            \"output\": [wandb.Image(np.concatenate([validation_y[i], o], axis=1)) for i, o in enumerate(output)]\n",
    "        }, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the generator\n",
    "gen = my_generator(2, train_dir)\n",
    "videos, next_frame = next(gen)\n",
    "videos[0].shape\n",
    "next_frame[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "imshow(videos[0][:,:,0:3])\n",
    "figure()\n",
    "imshow(videos[0][:,:,3:6])\n",
    "figure()\n",
    "imshow(videos[0][:,:,6:9])\n",
    "figure()\n",
    "imshow(videos[0][:,:,9:12])\n",
    "\n",
    "figure()\n",
    "imshow(next_frame[0][:,:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for measuring how similar two images are\n",
    "def perceptual_distance(y_true, y_pred):\n",
    "    y_true *= 255.\n",
    "    y_pred *= 255.\n",
    "    rmean = (y_true[:, :, :, 0] + y_pred[:, :, :, 0]) / 2\n",
    "    r = y_true[:, :, :, 0] - y_pred[:, :, :, 0]\n",
    "    g = y_true[:, :, :, 1] - y_pred[:, :, :, 1]\n",
    "    b = y_true[:, :, :, 2] - y_pred[:, :, :, 2]\n",
    "\n",
    "    return K.mean(K.sqrt((((512+rmean)*r*r)/256) + 4*g*g + (((767-rmean)*b*b)/256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(config=hyperparams)\n",
    "config = wandb.config\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(3, (3, 3), activation='relu', padding='same', input_shape=(config.height, config.width, 5 * 3)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[perceptual_distance])\n",
    "\n",
    "model.fit_generator(my_generator(config.batch_size, train_dir),\n",
    "                    steps_per_epoch=steps_per_epoch//4,\n",
    "                    epochs=config.num_epochs, callbacks=[\n",
    "    ImageCallback(), WandbCallback()],\n",
    "    validation_steps=validation_steps//4,\n",
    "    validation_data=my_generator(config.batch_size, val_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model - just return the last layer\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Permute\n",
    "\n",
    "def slice(x):\n",
    "    return x[:,:,:,:, -1]\n",
    "\n",
    "wandb.init(config=hyperparams)\n",
    "config = wandb.config\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Reshape((96,96,5,3), input_shape=(config.height, config.width, 5 * 3)))\n",
    "model.add(Permute((1,2,4,3)))\n",
    "model.add(Lambda(slice, input_shape=(96,96,3,5), output_shape=(96,96,3)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[perceptual_distance])\n",
    "\n",
    "model.fit_generator(my_generator(config.batch_size, train_dir),\n",
    "                    steps_per_epoch=steps_per_epoch//4,\n",
    "                    epochs=config.num_epochs, callbacks=[\n",
    "    ImageCallback(), WandbCallback()],\n",
    "    validation_steps=validation_steps//4,\n",
    "    validation_data=my_generator(config.batch_size, val_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just return the last layer, functional style\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Permute, Input\n",
    "from keras.models import Model\n",
    "\n",
    "def slice(x):\n",
    "    return x[:,:,:,:, -1]\n",
    "\n",
    "wandb.init(config=hyperparams)\n",
    "config = wandb.config\n",
    "\n",
    "inp = Input((config.height, config.width, 5 * 3))\n",
    "reshaped = Reshape((96,96,5,3))(inp)\n",
    "permuted = Permute((1,2,4,3))(reshaped)\n",
    "last_layer = Lambda(slice, input_shape=(96,96,3,5), output_shape=(96,96,3))(permuted)\n",
    "model=Model(inputs=[inp], outputs=[last_layer])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[perceptual_distance])\n",
    "\n",
    "model.fit_generator(my_generator(config.batch_size, train_dir),\n",
    "                    steps_per_epoch=steps_per_epoch//4,\n",
    "                    epochs=config.num_epochs, callbacks=[\n",
    "    ImageCallback(), WandbCallback()],\n",
    "    validation_steps=validation_steps//4,\n",
    "    validation_data=my_generator(config.batch_size, val_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv3D\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Permute, Input, add, Conv3D\n",
    "from keras.models import Model\n",
    "\n",
    "def slice(x):\n",
    "    return x[:,:,:,:, -1]\n",
    "\n",
    "hyperparams[\"num_epochs\"] = 100\n",
    "wandb.init(config=hyperparams)\n",
    "config = wandb.config\n",
    "\n",
    "inp = Input((config.height, config.width, 5 * 3))\n",
    "reshaped = Reshape((96,96,5,3))(inp)\n",
    "permuted = Permute((1,2,4,3))(reshaped)\n",
    "last_layer = Lambda(slice, input_shape=(96,96,3,5), output_shape=(96,96,3))(permuted)\n",
    "conv_output = Conv3D(1, (3,3,3), padding=\"same\")(permuted)\n",
    "conv_output_reshape = Reshape((96,96,3))(conv_output)\n",
    "combined = add([last_layer, conv_output_reshape])\n",
    "\n",
    "model=Model(inputs=[inp], outputs=[combined])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[perceptual_distance])\n",
    "\n",
    "model.fit_generator(my_generator(config.batch_size, train_dir),\n",
    "                    steps_per_epoch=steps_per_epoch//4,\n",
    "                    epochs=config.num_epochs, callbacks=[\n",
    "    ImageCallback(), WandbCallback()],\n",
    "    validation_steps=validation_steps//4,\n",
    "    validation_data=my_generator(config.batch_size, val_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv3D with Gaussian Noise\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Permute, Input, add, Conv3D, GaussianNoise\n",
    "from keras.models import Model\n",
    "\n",
    "def slice(x):\n",
    "    return x[:,:,:,:, -1]\n",
    "\n",
    "wandb.init()\n",
    "\n",
    "inp = Input((config.height, config.width, 5 * 3))\n",
    "reshaped = Reshape((96,96,5,3))(inp)\n",
    "permuted = Permute((1,2,4,3))(reshaped)\n",
    "noise = GaussianNoise(0.1)(permuted)\n",
    "last_layer = Lambda(slice, input_shape=(96,96,3,5), output_shape=(96,96,3))(noise)\n",
    "conv_output = Conv3D(1, (3,3,3), padding=\"same\")(noise)\n",
    "conv_output_reshape = Reshape((96,96,3))(conv_output)\n",
    "combined = add([last_layer, conv_output_reshape])\n",
    "\n",
    "model=Model(inputs=[inp], outputs=[combined])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[perceptual_distance])\n",
    "\n",
    "model.fit_generator(my_generator(config.batch_size, train_dir),\n",
    "                    steps_per_epoch=steps_per_epoch//4,\n",
    "                    epochs=config.num_epochs, callbacks=[\n",
    "    ImageCallback(), WandbCallback()],\n",
    "    validation_steps=validation_steps//4,\n",
    "    validation_data=my_generator(config.batch_size, val_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2DLSTM with Gaussian Noise\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Permute, Input, add, Conv3D, GaussianNoise, ConvLSTM2D\n",
    "from keras.models import Model\n",
    "\n",
    "def slice(x):\n",
    "    return x[:,:,:,:, -1]\n",
    "\n",
    "wandb.init(config=hyperparams)\n",
    "config = wandb.config\n",
    "\n",
    "inp = Input((config.height, config.width, 5 * 3))\n",
    "reshaped = Reshape((96,96,5,3))(inp)\n",
    "permuted = Permute((1,2,4,3))(reshaped)\n",
    "noise = GaussianNoise(0.1)(permuted)\n",
    "last_layer = Lambda(slice, input_shape=(96,96,3,5), output_shape=(96,96,3))(noise)\n",
    "permuted_2 = Permute((4,1,2,3))(noise)\n",
    "\n",
    "conv_lstm_output_1 = ConvLSTM2D(6, (3,3), padding='same')(permuted_2)\n",
    "conv_output = Conv2D(3, (3,3), padding=\"same\")(conv_lstm_output_1)\n",
    "combined = add([last_layer, conv_output])\n",
    "\n",
    "model=Model(inputs=[inp], outputs=[combined])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[perceptual_distance])\n",
    "\n",
    "model.fit_generator(my_generator(config.batch_size, train_dir),\n",
    "                    steps_per_epoch=steps_per_epoch//4,\n",
    "                    epochs=config.num_epochs, callbacks=[\n",
    "    ImageCallback(), WandbCallback()],\n",
    "    validation_steps=validation_steps//4,\n",
    "    validation_data=my_generator(config.batch_size, val_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2DLSTM with Gaussian Noise\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Permute, Input, add, Conv3D, GaussianNoise, concatenate\n",
    "from keras.layers import ConvLSTM2D, BatchNormalization, TimeDistributed, Add\n",
    "from keras.models import Model\n",
    "\n",
    "def slice(x):\n",
    "    return x[:,:,:,:, -1]\n",
    "\n",
    "wandb.init(config=hyperparams)\n",
    "config = wandb.config\n",
    "\n",
    "c=4\n",
    "\n",
    "inp = Input((config.height, config.width, 5 * 3))\n",
    "reshaped = Reshape((96,96,5,3))(inp)\n",
    "permuted = Permute((1,2,4,3))(reshaped)\n",
    "noise = GaussianNoise(0.1)(permuted)\n",
    "last_layer = Lambda(slice, input_shape=(96,96,3,5), output_shape=(96,96,3))(noise)\n",
    "x = Permute((4,1,2,3))(noise)\n",
    "x =(ConvLSTM2D(filters=c, kernel_size=(3,3),padding='same',name='conv_lstm1', return_sequences=True))(x)\n",
    "\n",
    "c1=(BatchNormalization())(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x =(TimeDistributed(MaxPooling2D(pool_size=(2,2))))(c1)\n",
    "\n",
    "x =(ConvLSTM2D(filters=2*c,kernel_size=(3,3),padding='same',name='conv_lstm3',return_sequences=True))(x)\n",
    "c2=(BatchNormalization())(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x =(TimeDistributed(MaxPooling2D(pool_size=(2,2))))(c2)\n",
    "x =(ConvLSTM2D(filters=4*c,kernel_size=(3,3),padding='same',name='conv_lstm4',return_sequences=True))(x)\n",
    "\n",
    "x =(TimeDistributed(UpSampling2D(size=(2, 2))))(x)\n",
    "x =(ConvLSTM2D(filters=4*c,kernel_size=(3,3),padding='same',name='conv_lstm5',return_sequences=True))(x)\n",
    "x =(BatchNormalization())(x)\n",
    "\n",
    "x =(ConvLSTM2D(filters=2*c,kernel_size=(3,3),padding='same',name='conv_lstm6',return_sequences=True))(x)\n",
    "x =(BatchNormalization())(x)\n",
    "x = Add()([c2, x])\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x =(TimeDistributed(UpSampling2D(size=(2, 2))))(x)\n",
    "x =(ConvLSTM2D(filters=c,kernel_size=(3,3),padding='same',name='conv_lstm7',return_sequences=False))(x)\n",
    "x =(BatchNormalization())(x)\n",
    "combined = concatenate([last_layer, x])\n",
    "combined = Conv2D(3, (1,1))(combined)\n",
    "model=Model(inputs=[inp], outputs=[combined])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[perceptual_distance])\n",
    "\n",
    "model.fit_generator(my_generator(config.batch_size, train_dir),\n",
    "                    steps_per_epoch=steps_per_epoch//4,\n",
    "                    epochs=config.num_epochs, callbacks=[\n",
    "    ImageCallback(), WandbCallback()],\n",
    "    validation_steps=validation_steps//4,\n",
    "    validation_data=my_generator(config.batch_size, val_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
